from itertools import combinations
import lightgbm as lgb
import numpy as np
import pandas as pd
from sklearn import metrics
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
from sklearn.decomposition import PCA
from sklearn.ensemble import HistGradientBoostingClassifier
import sklearn
from sklearn.ensemble import VotingClassifier

print('Loading data...')

y = np.load('./label.npy')

x1 = np.load('./f1.npy')
# ...
x15 = np.load('/f15.npy')
x_list = [x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15]

x_index = [i for i in range(len(x_list))]
comb = combinations(x_index, 1)

best_acc, best_recall, best_prec, best_f = 0, 0, 0, 0
best_acc_index, best_recall_index, best_prec_index, best_f_index = 0, 0, 0, 0

for i in list(comb):
    print(i)
    x = pd.DataFrame(np.concatenate([x_list[j] for j in i], axis=1))
    x = x.replace([np.inf, -np.inf], np.nan)

    imp_median = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
    x = imp_median.fit_transform(x)

    scaler = StandardScaler()
    x = scaler.fit_transform(x)
    n_fold = 10
    # xgb = xgb.XGBClassifier(n_estimators=300, random_state=42,max_depth = 63,learning_rate=.2)
    # rf = RandomForestClassifier(max_depth=63, n_estimators=300, random_state=42)
    # hist = HistGradientBoostingClassifier(max_iter=300, learning_rate=0.1,random_state=42)#93.19
    lgbm = lgb.LGBMClassifier(n_estimators=200,
                              boosting_type="gbdt",
                              learning_rate=0.2,
                              num_leaves=217,
                              max_depth=28,
                              verbosity=-1
                              )
    kf = KFold(n_splits=n_fold, shuffle=True, random_state=42)
    acc_list = []
    metric_list = []
    for train_index, test_index in kf.split(x, y):
        X_train, X_test = x[train_index], x[test_index]
        y_train, y_test = y[train_index], y[test_index]
        lgbm.fit(X_train, y_train)
        y_pred = lgbm.predict(X_test)
        acc = lgbm.score(X_test, y_test)
        metric = metrics.precision_recall_fscore_support(y_test, y_pred)
        acc_list.append(acc)
        metric_list.append(metric)
    print('-' * 30)
    acc = sum(acc_list) / n_fold
    precision_0 = sum([metric[0][0] for metric in metric_list]) / n_fold
    recall_0 = sum([metric[1][0] for metric in metric_list]) / n_fold
    f_score_0 = sum([metric[2][0] for metric in metric_list]) / n_fold
    precision_1 = sum([metric[0][1] for metric in metric_list]) / n_fold
    recall_1 = sum([metric[1][1] for metric in metric_list]) / n_fold
    f_score_1 = sum([metric[2][1] for metric in metric_list]) / n_fold

    if acc > best_acc:
        best_acc = acc
        best_acc_index = i

    if precision_1 > best_prec:
        best_prec = precision_1
        best_prec_index = i

    if recall_1 > best_recall:
        best_recall = recall_1
        best_recall_index = i

    if f_score_1 > best_f:
        best_f = f_score_1
        best_f_index = i

    print(f"Accuracy: {acc * 100:.2f}")
    print(f"Precision-0: {precision_0 * 100:.2f}")
    print(f"Recall-0: {recall_0 * 100:.2f}")
    print(f"F-Score-0: {f_score_0 * 100:.2f}")
    print(f"Precision-1: {precision_1 * 100:.2f}")
    print(f"Recall-1: {recall_1 * 100:.2f}")
    print(f"F-Score-1: {f_score_1 * 100:.2f}")
    print('-' * 30)

print(f"{best_acc*100=:.2f} {best_acc_index=}")
print(f"{best_prec*100=:.2f} {best_prec_index=}")
print(f"{best_recall*100=:.2f} {best_recall_index=}")
print(f"{best_f*100=:.2f} {best_f_index=}")
